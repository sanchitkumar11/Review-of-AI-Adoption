{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d66d6d46",
   "metadata": {},
   "source": [
    "# Sentiment Analysis in NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bc607269",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_terms = [\"Artificial Intelligence\", \"Machine Learning\", \"Deep Learning\", \"Neural Network\", \"Natural Language Processing\", \"Supervised Learning\", \"Unsupervised Learning\", \"Reinforcement Learning\", \"Generative Adversarial Networks\", \"Convolutional Neural Networks\", \"Recurrent Neural Networks\", \"Transfer Learning\", \"Data Mining\", \"Big Data\", \"Algorithm\",\"large language models\",\"llms\",\"robotics\",\"Chatbot\", \"Robotic Process Automation\", \"Computer Vision\", \"Image Recognition\", \"Speech Recognition\", \"Text Analytics\", \"Sentiment Analysis\", \"Autonomous Vehicles\", \"Internet of Things\", \"Edge Computing\", \"Quantum Computing\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35140c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_terms = [\"Artificial Intelligence\", \"Machine Learning\", \"Deep Learning\", \"Neural Network\", \"Natural Language Processing\", \"Supervised Learning\", \"Unsupervised Learning\", \"Reinforcement Learning\", \"Generative Adversarial Networks\", \"Convolutional Neural Networks\", \"Recurrent Neural Networks\", \"Transfer Learning\", \"Data Mining\", \"Big Data\", \"Algorithm\",\"large language models\",\"llms\",\"robotics\",\"Chatbot\", \"Robotic Process Automation\", \"Computer Vision\", \"Image Recognition\", \"Speech Recognition\", \"Text Analytics\", \"Sentiment Analysis\", \"Autonomous Vehicles\", \"Internet of Things\", \"Edge Computing\", \"Quantum Computing\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af10b4f",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3925e68",
   "metadata": {},
   "source": [
    "#### Running FinancialBert for sentiment analysis - not great results so tried more sentiment analysis models from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a01d64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.read_parquet('df_analysis.parquet', engine='pyarrow')\n",
    "#adding this now to do sentiment over time - get sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e7d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained(\"ahmedrachid/FinancialBERT-Sentiment-Analysis\", num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"ahmedrachid/FinancialBERT-Sentiment-Analysis\")\n",
    "\n",
    "# Define the maximum length for the text chunks. BERT typically works with a max_length of 512.\n",
    "max_length = 512\n",
    "\n",
    "# Function to apply sentiment analysis and manage text length\n",
    "def get_sentiment_and_score(text):\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(text, truncation=True, padding='longest', max_length=max_length, return_tensors='pt')\n",
    "    \n",
    "    # Get the model's output\n",
    "    output = model(**inputs)\n",
    "\n",
    "    # Get the sentiment\n",
    "    sentiment = output.logits.argmax(dim=1).item()\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    probabilities = torch.nn.functional.softmax(output.logits, dim=-1)\n",
    "\n",
    "    # Get the confidence score\n",
    "    confidence_score = probabilities.max(dim=-1).values.item()\n",
    "\n",
    "    # Convert the sentiment label from integer to string\n",
    "    if sentiment == 0:\n",
    "        sentiment = 'negative'\n",
    "    elif sentiment == 1:\n",
    "        sentiment = 'neutral'\n",
    "    else:\n",
    "        sentiment = 'positive'\n",
    "\n",
    "    return sentiment, confidence_score\n",
    "\n",
    "# Apply the function to the 'cleaned_text' column\n",
    "df_filtered_sample['sentiment_finbert_title'], df_filtered_sample['confidence_score'] = zip(*df_filtered_sample['cleaned_text'].map(get_sentiment_and_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7254bd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neutral     741\n",
       "positive    259\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value counts for sentiment column\n",
    "df_filtered_sample['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9081199c",
   "metadata": {},
   "source": [
    "### Trying sentiment using siebert/sentiment-roberta-large-english - not good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba6f0dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d01f0c09e0443f98d75bd1470f010a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1305a3d5e4475a9257911513d478ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b16d418d6384e1cb4565567856c71e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/256 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a406b2d1ab46cea9051b17867238f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d998460aa5546a698d3be0135b755d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e3cd674c2543d3a1dacc24f87edcd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9988656044006348}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\")\n",
    "print(sentiment_analysis(\"I love this!\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5450fbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 42min 58s, sys: 2.37 s, total: 2h 43min\n",
      "Wall time: 10min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"siebert/sentiment-roberta-large-english\")\n",
    "\n",
    "# Split your data into batches\n",
    "batch_size = 100\n",
    "batches = [df_filtered_sample['cleaned_text'][i:i + batch_size] for i in range(0,df_filtered_sample['cleaned_text'].shape[0],batch_size)]\n",
    "\n",
    "# Apply the model to each batch and combine the results\n",
    "sentiments = []\n",
    "for batch in batches:\n",
    "    results = sentiment_analysis(list(batch), truncation=True, padding='longest', max_length=512)\n",
    "    batch_sentiments = [1 if result['label'] == 'positive' else 0 for result in results]\n",
    "    sentiments.extend(batch_sentiments)\n",
    "\n",
    "# Assign the results to your dataframe\n",
    "df_filtered_sample['sentiment'] = sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c0df567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_sample['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6a9d0",
   "metadata": {},
   "source": [
    "#### roberta-base-sentiment - better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc69598e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51min 41s, sys: 875 ms, total: 51min 42s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "# Split your data into batches\n",
    "batch_size = 100\n",
    "batches = [df_filtered_sample['cleaned_text'][i:i + batch_size] for i in range(0,df_filtered_sample['cleaned_text'].shape[0],batch_size)]\n",
    "\n",
    "# Apply the model to each batch and combine the results\n",
    "sentiments = []\n",
    "for batch in batches:\n",
    "    results = sentiment_analysis(list(batch), truncation=True, padding='longest', max_length=512)\n",
    "    batch_sentiments = [result['label'] for result in results]  # Directly use the model's output\n",
    "    sentiments.extend(batch_sentiments)\n",
    "\n",
    "# Assign the results to your dataframe\n",
    "df_filtered_sample['sentiment_roberta_base'] = sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b17fc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL_1    987\n",
       "LABEL_0      7\n",
       "LABEL_2      6\n",
       "Name: sentiment_roberta_base, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_sample['sentiment_roberta_base'].value_counts()\n",
    "#800 neutral for title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "83f37d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df89b20fb80c41de885fab77d346895e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd258f74985744febff4d30360d3fca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6edc35e55f4ced8328d422568623a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1d61bae39d4c44a0578841b32173ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75afd9caf2d0417a9d75df0d080f15d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2037aa1387d48da83eb4913a6a250c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1657707760478588619d3906d4bcc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 29s, sys: 1.04 s, total: 5min 30s\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"shashanksrinath/News_Sentiment_Analysis\")\n",
    "\n",
    "# Split your data into batches\n",
    "batch_size = 100\n",
    "batches = [df_filtered_sample['clean_title'][i:i + batch_size] for i in range(0,df_filtered_sample['clean_title'].shape[0],batch_size)]\n",
    "\n",
    "# Apply the model to each batch and combine the results\n",
    "sentiments = []\n",
    "for batch in batches:\n",
    "    results = sentiment_analysis(list(batch), truncation=True, padding='longest', max_length=512)\n",
    "    batch_sentiments = [result['label'] for result in results]  # Directly use the model's output\n",
    "    sentiments.extend(batch_sentiments)\n",
    "\n",
    "# Assign the results to your dataframe\n",
    "df_filtered_sample['sentiment_srikanth_title'] = sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e704e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     923\n",
       "Positive     40\n",
       "Negative     37\n",
       "Name: sentiment_srikanth_title, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_sample['sentiment_srikanth_title'].value_counts()\n",
    "#1000 neutral for text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a65a4",
   "metadata": {},
   "source": [
    "#### tried another model called news_sentiment_analysis - not good results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cf7bb392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51min, sys: 1.08 s, total: 51min 1s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"shashanksrinath/News_Sentiment_Analysis\")\n",
    "\n",
    "# Split your data into batches\n",
    "batch_size = 100\n",
    "batches = [df_filtered_sample['cleaned_text'][i:i + batch_size] for i in range(0,df_filtered_sample['cleaned_text'].shape[0],batch_size)]\n",
    "\n",
    "# Apply the model to each batch and combine the results\n",
    "sentiments = []\n",
    "for batch in batches:\n",
    "    results = sentiment_analysis(list(batch), truncation=True, padding='longest', max_length=512)\n",
    "    batch_sentiments = [result['label'] for result in results]  # Directly use the model's output\n",
    "    sentiments.extend(batch_sentiments)\n",
    "\n",
    "# Assign the results to your dataframe\n",
    "df_filtered_sample['sentiment_srikanth'] = sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d190046e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral    1000\n",
       "Name: sentiment_srikanth, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_sample['sentiment_srikanth'].value_counts()\n",
    "#923 neurtral for title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9d368d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a6d9fa36184958a6f6f755bc52582f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778a3a70c6bd49c8b5c8e006a3aa8237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf906d0879743b0b9685be1626902b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a22db9209394b229f85e2da1dbf234a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33b5c2a1a66463b85df822ebeffcc3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50min 39s, sys: 1.76 s, total: 50min 41s\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "# Split your data into batches\n",
    "batch_size = 100\n",
    "batches = [df_filtered_sample['cleaned_text'][i:i + batch_size] for i in range(0,df_filtered_sample['cleaned_text'].shape[0],batch_size)]\n",
    "\n",
    "# Apply the model to each batch and combine the results\n",
    "sentiments = []\n",
    "for batch in batches:\n",
    "    results = sentiment_analysis(list(batch), truncation=True, padding='longest', max_length=512)\n",
    "    batch_sentiments = [result['label'] for result in results]  # Directly use the model's output\n",
    "    sentiments.extend(batch_sentiments)\n",
    "\n",
    "# Assign the results to your dataframe\n",
    "df_filtered_sample['roberta_latest'] = sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "700367ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 18s, sys: 1.24 s, total: 4min 19s\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "# Split your data into batches\n",
    "batch_size = 100\n",
    "batches = [df_filtered_sample['clean_title'][i:i + batch_size] for i in range(0,df_filtered_sample['clean_title'].shape[0],batch_size)]\n",
    "\n",
    "# Apply the model to each batch and combine the results\n",
    "sentiments = []\n",
    "for batch in batches:\n",
    "    results = sentiment_analysis(list(batch), truncation=True, padding='longest', max_length=512)\n",
    "    batch_sentiments = [result['label'] for result in results]  # Directly use the model's output\n",
    "    sentiments.extend(batch_sentiments)\n",
    "\n",
    "# Assign the results to your dataframe\n",
    "# df_filtered_sample['roberta_latest_title'] = sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94c8dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    # Preprocess and encode the text\n",
    "    encoded_input = tokenizer(text, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "    # Get the model's output\n",
    "    output = model(**encoded_input)\n",
    "    scores = output.logits.detach().numpy()\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    probabilities = softmax(scores, axis=-1)[0]\n",
    "\n",
    "    # Create a dictionary mapping labels to their probabilities\n",
    "    label_probs = {f'LABEL_{i}': prob for i, prob in enumerate(probabilities)}\n",
    "    \n",
    "    # Assign the label with the highest probability that exceeds its threshold\n",
    "    sentiment_label = 'unclassified'  # Default label if no thresholds are exceeded\n",
    "    for label, prob in label_probs.items():\n",
    "        if prob > thresholds[label]:  # Check if the probability exceeds the threshold\n",
    "            sentiment_label = label\n",
    "            break  # Stop checking other labels\n",
    "\n",
    "    return sentiment_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0c0a6eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 41s, sys: 200 ms, total: 5min 41s\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Apply the function to the 'cleaned_title' column\n",
    "df_filtered_sample['roberta_latest_title'] = df_filtered_sample['clean_title'].apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c432d5",
   "metadata": {},
   "source": [
    "#### Decided to use cardiffnlp/twitter-roberta-base-sentiment-latest on title because it is able to seperate positive and negative the best - defined thresholds for negative positive and neutral to create the best seperation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bfce41",
   "metadata": {},
   "source": [
    "# Roberta Base Sentiment Latest on Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c6b1924b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15h 42min 12s, sys: 33.8 s, total: 15h 42min 46s\n",
      "Wall time: 58min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_analysis['roberta_latest_title_sentiment'] = df_analysis['clean_title'].apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "580e945d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL_2    100996\n",
       "LABEL_0     46684\n",
       "LABEL_1     16417\n",
       "Name: roberta_latest_title_sentiment, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis['roberta_latest_title_sentiment'].value_counts()\n",
    "#0 is negative \n",
    "#2 is positive\n",
    "#1 is neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706c454e",
   "metadata": {},
   "source": [
    "# Bertopics on positive sentiment news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4d72f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing neutrals\n",
    "df_analysis = df_analysis[df_analysis['roberta_latest_title_sentiment'] != 'LABEL_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ea51c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df_analysis[df_analysis['roberta_latest_title_sentiment'] == 'LABEL_2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ee74315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to perform aspect-based sentiment analysis\n",
    "def perform_aspect_sentiment_analysis(text):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    # Analyze sentiment for each sentence\n",
    "    sentiment_scores = []\n",
    "    for sentence in sentences:\n",
    "        sentiment = sia.polarity_scores(sentence)\n",
    "        sentiment_scores.append(sentiment['compound'])\n",
    "    \n",
    "    # Return the average sentiment score for the text\n",
    "    return sum(sentiment_scores) / len(sentiment_scores)\n",
    "\n",
    "# Apply aspect-based sentiment analysis to the 'text' column of your DataFrame\n",
    "chatgpt_df_1['aspect_sentiment'] = chatgpt_df_1['Document'].apply(perform_aspect_sentiment_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "a34926d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 5882 analyzed documents, the sentiment towards innovation is as follows:\n",
      "Positive: 1681 documents (28.58%)\n",
      "Negative: 11 documents (0.19%)\n",
      "Neutral: 0 documents (0.00%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to perform targeted sentiment analysis\n",
    "def perform_targeted_sentiment_analysis(row, target_entity):\n",
    "    text = row['Document']\n",
    "    sentiment_scores = analyzer.polarity_scores(text)\n",
    "    compound_score = sentiment_scores['compound']\n",
    "    \n",
    "    # Check if the target entity is mentioned in the text\n",
    "    if target_entity.lower() in text.lower():\n",
    "        if compound_score >= 0.05:\n",
    "            sentiment = 'positive'\n",
    "        elif compound_score <= -0.05:\n",
    "            sentiment = 'negative'\n",
    "        else:\n",
    "            sentiment = 'neutral'\n",
    "        return sentiment\n",
    "    else:\n",
    "        return 'not mentioned'\n",
    "\n",
    "# Example target entity\n",
    "target_entity = \"innovation\"\n",
    "\n",
    "# Perform targeted sentiment analysis on the chatgpt_df dataframe\n",
    "chatgpt_df['Sentiment_innovation'] = chatgpt_df.apply(perform_targeted_sentiment_analysis, target_entity=target_entity, axis=1)\n",
    "\n",
    "# Interpret the sentiment analysis results\n",
    "sentiment_counts = chatgpt_df['Sentiment_innovation'].value_counts()\n",
    "positive_count = sentiment_counts.get('positive', 0)\n",
    "negative_count = sentiment_counts.get('negative', 0)\n",
    "neutral_count = sentiment_counts.get('neutral', 0)\n",
    "\n",
    "# Calculate the percentage of positive, negative, and neutral sentiment\n",
    "total_count = len(chatgpt_df)\n",
    "positive_percentage = (positive_count / total_count) * 100\n",
    "negative_percentage = (negative_count / total_count) * 100\n",
    "neutral_percentage = (neutral_count / total_count) * 100\n",
    "\n",
    "# Interpretation of sentiment analysis results\n",
    "interpretation = f\"In the {total_count} analyzed documents, the sentiment towards {target_entity} is as follows:\\n\"\n",
    "interpretation += f\"Positive: {positive_count} documents ({positive_percentage:.2f}%)\\n\"\n",
    "interpretation += f\"Negative: {negative_count} documents ({negative_percentage:.2f}%)\\n\"\n",
    "interpretation += f\"Neutral: {neutral_count} documents ({neutral_percentage:.2f}%)\"\n",
    "\n",
    "# Print the interpretation\n",
    "print(interpretation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "edca97b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics_negative = df_topics_positives_100\n",
    "#because im copying code from the negative_sentiment_analysis\n",
    "#will change back the variable name later"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
